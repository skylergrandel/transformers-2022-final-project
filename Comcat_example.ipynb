{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82IGZB-Tz-Nc",
        "outputId": "d7a2ba36-2fd5-4955-9001-c3278c7afd6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 56.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up6I3DhizVxD",
        "outputId": "0f0a01fc-0937-4245-b820-f0a5b7c9c328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [{'label': 'LABEL_5', 'score': 0.6703650951385498}]\n"
          ]
        }
      ],
      "source": [
        "# This is a basic example use. It is exactly what is given in the huggingface model card\n",
        "\n",
        "from transformers import RobertaTokenizerFast, AutoModelForSequenceClassification, TextClassificationPipeline\n",
        "import torch\n",
        "\n",
        "def preprocess(comment):\n",
        "  comment = ''.join(e for e in comment if (e.isalnum() or e == ' '))\n",
        "  return comment\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # use whatever device works for you\n",
        "\n",
        "num_labels = 12\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(\"skylergrandel/Comcat\", num_labels=num_labels).to(DEVICE))\n",
        "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=DEVICE)\n",
        "\n",
        "prediction = classifier(preprocess('/* This is a comment that we want to classify */'))\n",
        "print('Prediction:', prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that index 0 and 8 are taken from a dataset of unlabeled comments, because I didn't want to write a long comment\n",
        "# All of the other ones were just made up\n",
        "text = [\n",
        "    '''/**\n",
        "* Comparison function for tr_announce_requests.\n",
        "*\n",
        "* The primary key (amount of data transferred) is used to prioritize\n",
        "* tracker announcements of active torrents. The remaining keys are\n",
        "* used to satisfy the uniqueness requirement of a sorted tr_ptrArray.\n",
        "*/''',\n",
        "    '/* sum contains the sum of all of the numbers in the list */',\n",
        "    '/* walk through the list, turning all of the 0s to -1s */',\n",
        "    '/* if the number is even, put it in A; otherwise, put it in B */',\n",
        "    '/* We loop in reverse because it is the most efficient way */',\n",
        "    '/* This is a useless comment */',\n",
        "    '/* This should be called by a collector thread */',\n",
        "    '/* from example in the glib documentation at www.examplewebsite.com/glibdocs/get */',\n",
        "    '''\n",
        "    /* -*- Mode: C; tab-width: 8; indent-tabs-mode: t; c-basic-offset: 8; coding: utf-8 -*- *//*\n",
        "      * This file is part of GtkSourceView\n",
        "      *\n",
        "      * Copyright (C) 2003 - Gustavo Giráldez\n",
        "      * Copyright (C) 2006, 2013 - Paolo Borelli\n",
        "      * Copyright (C) 2013, 2016 - Sébastien Wilmet\n",
        "      *\n",
        "      * GtkSourceView is free software; you can redistribute it and/or\n",
        "      * modify it under the terms of the GNU Lesser General Public\n",
        "      * License as published by the Free Software Foundation; either\n",
        "      * version 2.1 of the License, or (at your option) any later version.\n",
        "      *\n",
        "      * GtkSourceView is distributed in the hope that it will be useful,\n",
        "      * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "      * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n",
        "      * Lesser General Public License for more details.\n",
        "      *\n",
        "      * You should have received a copy of the GNU Lesser General Public\n",
        "      * License along with this library; if not, write to the Free Software\n",
        "      * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n",
        "      */\n",
        "    ''',\n",
        "    '/* The following tests are to test foo() */',\n",
        "    '/* int y = x+10 */',\n",
        "    '/* TODO: add failure test cases */',\n",
        "]"
      ],
      "metadata": {
        "id": "dxsIp__u1GnN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "  prediction = classifier(preprocess(text[i]))\n",
        "  print('Prediction for text[', i, ']:', prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7DcUC5K5xpp",
        "outputId": "7457ba5f-be25-416d-adbd-338dbfc50d48"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for text[ 0 ]: [{'label': 'LABEL_0', 'score': 0.8686641454696655}]\n",
            "Prediction for text[ 1 ]: [{'label': 'LABEL_1', 'score': 0.7577952146530151}]\n",
            "Prediction for text[ 2 ]: [{'label': 'LABEL_2', 'score': 0.9838972687721252}]\n",
            "Prediction for text[ 3 ]: [{'label': 'LABEL_3', 'score': 0.9059826135635376}]\n",
            "Prediction for text[ 4 ]: [{'label': 'LABEL_4', 'score': 0.4900676906108856}]\n",
            "Prediction for text[ 5 ]: [{'label': 'LABEL_5', 'score': 0.9692336916923523}]\n",
            "Prediction for text[ 6 ]: [{'label': 'LABEL_6', 'score': 0.9262851476669312}]\n",
            "Prediction for text[ 7 ]: [{'label': 'LABEL_7', 'score': 0.2945345342159271}]\n",
            "Prediction for text[ 8 ]: [{'label': 'LABEL_8', 'score': 0.4667740762233734}]\n",
            "Prediction for text[ 9 ]: [{'label': 'LABEL_9', 'score': 0.4376959204673767}]\n",
            "Prediction for text[ 10 ]: [{'label': 'LABEL_10', 'score': 0.6370751261711121}]\n",
            "Prediction for text[ 11 ]: [{'label': 'LABEL_11', 'score': 0.9256995916366577}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Of course, some categories perform better than others. \n",
        "# For example, we have limited training data for categories 7 and 8\n",
        "\n",
        "# One interesting failure case is when we use informal language for one of the more useful categories, \n",
        "# because the model seems to think that comments with informal or indirect language belong in category 5\n",
        "\n",
        "# This is a failure case that I made up\n",
        "print('This should be LABEL_2:', classifier(preprocess('/* We just kinda want to mix around the letters in this string */')))\n",
        "\n",
        "# This is a real failure case from the test set\n",
        "print('This should be LABEL_4:', classifier(preprocess('/* Windows 98 appears to asynchronously create and remove  *//* writable memory mappings, for reasons we havent yet    *//* understood.  Since we look for writable regions to      *//* determine the root set, we may try to mark from an      *//* address range that disappeared since we started the     *//* collection.  Thus we have to recover from faults here.  *//* This code does not appear to be necessary for Windows   *//* 95/NT/2000. Note that this code should never generate   *//* an incremental GC write fault.                          */')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F96G62Sx_lSz",
        "outputId": "9a5c6d7b-5fe4-48d6-97b0-4a689805a05c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This should be LABEL_2: [{'label': 'LABEL_5', 'score': 0.9368220567703247}]\n",
            "This should be LABEL_4: [{'label': 'LABEL_5', 'score': 0.9527665972709656}]\n"
          ]
        }
      ]
    }
  ]
}